{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.chat_models import ChatLlamaAPI\n",
    "from PIL import Image\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from transformers import LlavaForConditionalGeneration, LlavaProcessor\n",
    "import torch\n",
    "\n",
    "class ImageCaptioner:\n",
    "    def __init__(self, model_name=\"llava-hf/llava-1.5-7b-hf\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.model = LlavaForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        self.processor = LlavaProcessor.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.results = {}\n",
    "\n",
    "    def caption_image(self, image_path, prompt=\"Describe this image in detail.\"):\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            inputs = self.processor(\n",
    "                images=image, \n",
    "                text=prompt, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=200,\n",
    "                num_beams=4,\n",
    "                temperature=0.8\n",
    "            )\n",
    "            \n",
    "            caption = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            return caption\n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\"\n",
    "\n",
    "    def process_folder(self, folder_path, output_format=\"both\"):\n",
    "        \"\"\"\n",
    "        Process all images in a folder\n",
    "        output_format: \"txt\", \"json\", or \"both\"\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Prepare output files\n",
    "        txt_file = f\"captions_{timestamp}.txt\"\n",
    "        json_file = f\"captions_{timestamp}.json\"\n",
    "        \n",
    "        # Get list of image files\n",
    "        image_files = [f for f in os.listdir(folder_path) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "        \n",
    "        # Process images with progress bar\n",
    "        for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            caption = self.caption_image(image_path)\n",
    "            self.results[filename] = caption\n",
    "            \n",
    "            # Write to txt file if requested\n",
    "            if output_format in [\"txt\", \"both\"]:\n",
    "                with open(txt_file, 'a', encoding='utf-8') as f:\n",
    "                    f.write(f\"Image: {filename}\\nCaption: {caption}\\n\\n\")\n",
    "            \n",
    "            # Write to JSON if requested\n",
    "            if output_format in [\"json\", \"both\"]:\n",
    "                with open(json_file, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(self.results, f, indent=4)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    captioner = ImageCaptioner()\n",
    "    folder_path = \"path/to/your/images\"\n",
    "    results = captioner.process_folder(folder_path)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nProcessed {len(results)} images\")\n",
    "    print(f\"Results saved to captions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt/json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
