{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_cpp\n",
    "from PIL import Image\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def download_model_files(base_url, model_files):\n",
    "    \"\"\"Download model files if they don't exist\"\"\"\n",
    "    for filename in model_files:\n",
    "        if not Path(filename).exists():\n",
    "            url = f\"{base_url}/resolve/main/{filename}\"\n",
    "            response = requests.get(url)\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load and return a PIL Image\"\"\"\n",
    "    if image_path.startswith(('http://', 'https://')):\n",
    "        return Image.open(requests.get(image_path, stream=True).raw)\n",
    "    return Image.open(image_path)\n",
    "\n",
    "def caption_image(image_path, model_path=\"llava-llama-3-8b-v1_1-f16.gguf\", \n",
    "                 mmproj_path=\"llava-llama-3-8b-v1_1-mmproj-f16.gguf\"):\n",
    "    \"\"\"Generate a caption for the given image using LLaVA model\"\"\"\n",
    "    \n",
    "    # Initialize the LLaVA model\n",
    "    model = llama_cpp.LlamaVision(\n",
    "        model_path=model_path,\n",
    "        mmproj_path=mmproj_path,\n",
    "        n_ctx=4096,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Load the image\n",
    "    image = load_image(image_path)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = \"\"\"<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "<image>\n",
    "Describe this image<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate caption\n",
    "    response = model.create_chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"source\": image},\n",
    "                    {\"type\": \"text\", \"text\": \"Describe this image\"}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=512,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Model files to download\n",
    "    base_url = \"https://huggingface.co/xtuner/llava-llama-3-8b-v1_1-gguf\"\n",
    "    model_files = [\n",
    "        \"llava-llama-3-8b-v1_1-f16.gguf\",\n",
    "        \"llava-llama-3-8b-v1_1-mmproj-f16.gguf\"\n",
    "    ]\n",
    "    \n",
    "    # Download models if needed\n",
    "    download_model_files(base_url, model_files)\n",
    "    \n",
    "    # Test with an image\n",
    "    image_path = \"https://i.pinimg.com/736x/ab/4a/a1/ab4aa1119864bbae52fa8a99baf3f71e.jpg\"  # Replace with your image path\n",
    "    caption = caption_image(image_path)\n",
    "    print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
